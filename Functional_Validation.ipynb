{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Functional Validation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/spencer990330/work/blob/master/Functional_Validation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-B8U5lC33Wiu",
        "outputId": "f54a5e06-1ed7-4418-94e3-5a66807842dc"
      },
      "source": [
        "import nltk\n",
        "from nltk.corpus import wordnet as wn\n",
        "from nltk.corpus import genesis\n",
        "nltk.download('genesis')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "genesis_ic = wn.ic(genesis, False, 0.0)\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "from nltk.stem import SnowballStemmer\n",
        "from nltk.stem.lancaster import LancasterStemmer\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.linear_model import RidgeClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package genesis to /root/nltk_data...\n",
            "[nltk_data]   Package genesis is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "id": "NIEwECiL3fyU",
        "outputId": "75fcf5bb-ad1c-49ba-e8a4-d5be3112fe5e"
      },
      "source": [
        "data = pd.read_csv('/content/resume_data.csv')\n",
        "# Check to test the data quality. If all the source data has been read correctly to pandas dataframe, From data frame observation we infer that there is unwanted text in work_experience, Educations, skills, Links, Certificates and Additional Infomration columns. We need to clean the text in these columns. \n",
        "data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Resume_title</th>\n",
              "      <th>City</th>\n",
              "      <th>State</th>\n",
              "      <th>Description</th>\n",
              "      <th>work_experiences</th>\n",
              "      <th>Educations</th>\n",
              "      <th>Skills</th>\n",
              "      <th>Links</th>\n",
              "      <th>Certificates</th>\n",
              "      <th>Additional Information</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Java Developer</td>\n",
              "      <td>Tirur</td>\n",
              "      <td>Kerala</td>\n",
              "      <td>To prove myself dedicated, worthy and energeti...</td>\n",
              "      <td>{0: [{'wtitle:': 'Java Developer'}, {'wcompany...</td>\n",
              "      <td>{0: [{'e_title:': \"Bachelor's in Bachelor of C...</td>\n",
              "      <td>['Java (Less than 1 year)', ' Jsp (Less than 1...</td>\n",
              "      <td>['https://www.linkedin.com/in/mohamed-rihan-k-...</td>\n",
              "      <td>{0: [{'c_title:': 'Java Developer'}, {'c_durat...</td>\n",
              "      <td>\\nTechnical Expertise \\n• Operating Systems: W...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Software Developer</td>\n",
              "      <td>Bengaluru</td>\n",
              "      <td>Karnataka</td>\n",
              "      <td>Working as Software Developer at IngroInfo Sof...</td>\n",
              "      <td>{0: [{'wtitle:': 'JAVA DEVELOPER'}, {'wcompany...</td>\n",
              "      <td>{0: [{'e_title:': 'MCA in Master of Computer A...</td>\n",
              "      <td>['Programming Languages: Core Java', ' J2EE \\n...</td>\n",
              "      <td>['http://github.com/NK-PATEL/Train_Project', '...</td>\n",
              "      <td>{}</td>\n",
              "      <td>NONE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Java developer</td>\n",
              "      <td>Pune</td>\n",
              "      <td>Maharashtra</td>\n",
              "      <td>Looking for a challenging career which demands...</td>\n",
              "      <td>{0: [{'wtitle:': 'Java Developer'}, {'wcompany...</td>\n",
              "      <td>{0: [{'e_title:': \"Bachelor's in Electrical En...</td>\n",
              "      <td>['ECLIPSE (1 year)', ' HIBERNATE', ' SPRING (L...</td>\n",
              "      <td>[]</td>\n",
              "      <td>{}</td>\n",
              "      <td>\\nTECHNICAL SKILLS \\n \\nFrameworks: Spring, Sp...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Seeking innovative and challenging career assi...</td>\n",
              "      <td>Pune</td>\n",
              "      <td>Maharashtra</td>\n",
              "      <td>NONE</td>\n",
              "      <td>{0: [{'wtitle:': 'Java Developer'}, {'wcompany...</td>\n",
              "      <td>{0: [{'e_title:': 'BE in Computer'}, {'e_schoo...</td>\n",
              "      <td>['GIT', ' Angular 7', ' MAVEN', ' Java', ' Jen...</td>\n",
              "      <td>[]</td>\n",
              "      <td>{}</td>\n",
              "      <td>NONE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>NONE</td>\n",
              "      <td>Pune</td>\n",
              "      <td>Maharashtra</td>\n",
              "      <td>NONE</td>\n",
              "      <td>{0: [{'wtitle:': 'Java Developer'}, {'wcompany...</td>\n",
              "      <td>{0: [{'e_title:': 'Bachelor of Engineering in ...</td>\n",
              "      <td>['Project: HR Payroll Systems Role: Java Devel...</td>\n",
              "      <td>[]</td>\n",
              "      <td>{}</td>\n",
              "      <td>NONE</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                        Resume_title  ...                             Additional Information\n",
              "0                                     Java Developer  ...  \\nTechnical Expertise \\n• Operating Systems: W...\n",
              "1                                 Software Developer  ...                                               NONE\n",
              "2                                     Java developer  ...  \\nTECHNICAL SKILLS \\n \\nFrameworks: Spring, Sp...\n",
              "3  Seeking innovative and challenging career assi...  ...                                               NONE\n",
              "4                                               NONE  ...                                               NONE\n",
              "\n",
              "[5 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nBux38NiDFVr"
      },
      "source": [
        "data['Description'] = data['Description'].apply(str)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y0pNmmqwDDcu",
        "outputId": "11574781-a02f-4532-9ac1-e64736cfc41b"
      },
      "source": [
        "# Remove the urls first - Anything that has .com, .co.uk or www. is a url!\n",
        "def remove_urls(s):\n",
        "    s = re.sub('[^\\s]*.com[^\\s]*', \"\", s)\n",
        "    s = re.sub('[^\\s]*www.[^\\s]*', \"\", s)\n",
        "    s = re.sub('[^\\s]*.co.uk[^\\s]*', \"\", s)\n",
        "    return s\n",
        "\n",
        "data['Clean_Description'] = data['Description'].map(remove_urls)\n",
        "\n",
        "\n",
        "# Remove the star_words\n",
        "def remove_star_words(s):\n",
        "    return re.sub('[^\\s]*[\\*]+[^\\s]*', \"\", s)\n",
        "\n",
        "data['Clean_Description'] = data['Description'].map(remove_star_words)\n",
        "\n",
        "def remove_nums(s):\n",
        "    return re.sub('[^\\s]*[0-9]+[^\\s]*', \"\", s)\n",
        "\n",
        "data['Clean_Description'] = data['Description'].map(remove_nums)\n",
        "\n",
        "# Remove the punctuations\n",
        "from string import punctuation\n",
        "\n",
        "def remove_punctuation(s):\n",
        "    global punctuation\n",
        "    for p in punctuation:\n",
        "        s = s.replace(p, '')\n",
        "    return s\n",
        "\n",
        "data['Clean_Description'] = data['Description'].map(remove_punctuation)\n",
        "\n",
        "# Convert to lower case\n",
        "data['Clean_Description'] = data['Description'].map(lambda x: x.lower())\n",
        "\n",
        "corpus = \" \".join(data['Clean_Description'].tolist())\n",
        "\n",
        "\n",
        "\n",
        "data.head(5)\n",
        "data.loc[:,\"Clean_Description\"].head(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    to prove myself dedicated, worthy and energeti...\n",
              "1    working as software developer at ingroinfo sof...\n",
              "2    looking for a challenging career which demands...\n",
              "3                                                 none\n",
              "4                                                 none\n",
              "Name: Clean_Description, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CJT5unbm3mwR",
        "outputId": "65e3df0e-280a-4210-958c-9841e67ed064"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "import nltk\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "\n",
        "en_stopwords = stopwords.words('english')\n",
        "\n",
        "# define a function to remove stopwords from descriptions\n",
        "def remove_stopwords(s):\n",
        "    global en_stopwords\n",
        "    s = word_tokenize(s)\n",
        "    s = \" \".join([w for w in s if w not in en_stopwords])\n",
        "    return s\n",
        "\n",
        "# Create a new column of descriptions with no stopwords\n",
        "data['Clean_Description_no_stop'] = data['Clean_Description'].map(remove_stopwords)\n",
        "\n",
        "# make a corpus of all the words in the job description\n",
        "corpus = \" \".join(data['Clean_Description_no_stop'].tolist())\n",
        "\n",
        "# This is the NLTK function that breaks a string down to its tokens\n",
        "tokens = word_tokenize(corpus)\n",
        "\n",
        "answer = nltk.pos_tag(tokens)\n",
        "answer_pos = [a[1] for a in answer]\n",
        "\n",
        "all_pos = pd.Series(answer_pos)\n",
        "all_pos.value_counts().head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "NN     266108\n",
              "JJ     108281\n",
              "NNS     78262\n",
              ",       67191\n",
              "VBG     41200\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gadElDwY3nbv",
        "outputId": "52f012d5-1e19-44a5-9115-2e09de2ac2d9"
      },
      "source": [
        "from nltk.stem.wordnet import WordNetLemmatizer\n",
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "\n",
        "lmtzr = WordNetLemmatizer()\n",
        "\n",
        "# prepare corpus from the descriptions that dont have stopwords\n",
        " \n",
        "for i in range(len(data)):\n",
        " \n",
        "  corpus = data['Clean_Description_no_stop'][i]\n",
        "\n",
        "#tokenize words\n",
        "  tokenized_corpus = nltk.word_tokenize(corpus)\n",
        "\n",
        "# lemmatize these tokens\n",
        "  lemmatized_tokens = [lmtzr.lemmatize(token) for token in tokenized_corpus]\n",
        "\n",
        "# word frequencies for the lemmatized tokens\n",
        "  fd= nltk.FreqDist(lemmatized_tokens)\n",
        "  top_words_res = []\n",
        "  words_res=pd.Series([])\n",
        "  for key, value in fd.items():\n",
        "    top_words_res.append((key))\n",
        "    words_res[i]=top_words"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xgmCqAgtEm3T"
      },
      "source": [
        "y = top_words_res"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b5yp2NZNLGtq",
        "outputId": "81404bdb-028a-47af-a812-3d6972de558e"
      },
      "source": [
        "top_words_res"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['age',\n",
              " ':',\n",
              " '32',\n",
              " 'year',\n",
              " 'gender',\n",
              " 'male',\n",
              " 'functional',\n",
              " 'area',\n",
              " 'accounts/',\n",
              " 'finance/audit/e-',\n",
              " 'commerce',\n",
              " 'position',\n",
              " 'type',\n",
              " 'full',\n",
              " 'time',\n",
              " '.',\n",
              " 'home',\n",
              " 'town',\n",
              " 'howrah',\n",
              " 'preferred',\n",
              " 'location',\n",
              " 'india']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zcg7EURZXH-n",
        "outputId": "b6a28a48-39fb-49dd-f7e8-8dc51e6029f0"
      },
      "source": [
        "df = pd.read_csv(\"/content/job position.csv\")\n",
        "df.head(2)\n",
        "print(\"Data Shape:\", df.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Data Shape: (244768, 12)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nz3kNsJgXPBl",
        "outputId": "dbe0f7df-0cf4-4545-a43a-3ab2562d92a3"
      },
      "source": [
        "# Remove the urls first - Anything that has .com, .co.uk or www. is a url!\n",
        "def remove_urls(s):\n",
        "    s = re.sub('[^\\s]*.com[^\\s]*', \"\", s)\n",
        "    s = re.sub('[^\\s]*www.[^\\s]*', \"\", s)\n",
        "    s = re.sub('[^\\s]*.co.uk[^\\s]*', \"\", s)\n",
        "    return s\n",
        "\n",
        "df['Clean_Full_Descriptions'] = df['FullDescription'].map(remove_urls)\n",
        "# Remove the star_words\n",
        "def remove_star_words(s):\n",
        "    return re.sub('[^\\s]*[\\*]+[^\\s]*', \"\", s)\n",
        "\n",
        "df['Clean_Full_Descriptions'] = df['Clean_Full_Descriptions'].map(remove_star_words)\n",
        "\n",
        "def remove_nums(s):\n",
        "    return re.sub('[^\\s]*[0-9]+[^\\s]*', \"\", s)\n",
        "\n",
        "df['Clean_Full_Descriptions'] = df['Clean_Full_Descriptions'].map(remove_nums)\n",
        "\n",
        "# Remove the punctuations\n",
        "from string import punctuation\n",
        "\n",
        "def remove_punctuation(s):\n",
        "    global punctuation\n",
        "    for p in punctuation:\n",
        "        s = s.replace(p, '')\n",
        "    return s\n",
        "\n",
        "df['Clean_Full_Descriptions'] = df['Clean_Full_Descriptions'].map(remove_punctuation)\n",
        "\n",
        "# Convert to lower case\n",
        "df['Clean_Full_Descriptions'] = df['Clean_Full_Descriptions'].map(lambda x: x.lower())\n",
        "\n",
        "corpus = \" \".join(df['Clean_Full_Descriptions'].tolist())\n",
        "\n",
        "\n",
        "\n",
        "df.head(5)\n",
        "df.loc[:,\"Clean_Full_Descriptions\"].head(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    engineering systems analyst dorking surrey sal...\n",
              "1    stress engineer glasgow salary  to  we re curr...\n",
              "2    mathematical modeller  simulation analyst  ope...\n",
              "3    engineering systems analyst  mathematical mode...\n",
              "4    pioneer miser  engineering systems analyst dor...\n",
              "Name: Clean_Full_Descriptions, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 150
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sZOkvdv-XknK",
        "outputId": "845f9a34-eeba-4b48-c62b-991db05af97b"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "import nltk\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "\n",
        "en_stopwords = stopwords.words('english')\n",
        "\n",
        "# define a function to remove stopwords from descriptions\n",
        "def remove_stopwords(s):\n",
        "    global en_stopwords\n",
        "    s = word_tokenize(s)\n",
        "    s = \" \".join([w for w in s if w not in en_stopwords])\n",
        "    return s\n",
        "\n",
        "# Create a new column of descriptions with no stopwords\n",
        "df['Clean_Full_Descriptions_no_stop'] = df['Clean_Full_Descriptions'].map(remove_stopwords)\n",
        "\n",
        "# make a corpus of all the words in the job description\n",
        "corpus = \" \".join(df['Clean_Full_Descriptions_no_stop'].tolist())\n",
        "\n",
        "# This is the NLTK function that breaks a string down to its tokens\n",
        "tokens = word_tokenize(corpus)\n",
        "\n",
        "answer = nltk.pos_tag(tokens)\n",
        "answer_pos = [a[1] for a in answer]\n",
        "\n",
        "all_pos = pd.Series(answer_pos)\n",
        "all_pos.value_counts().head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "NN     14323579\n",
              "JJ      6846127\n",
              "NNS     4866344\n",
              "VBG     2442038\n",
              "VBP     1652790\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 151
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WbyAJgwAXoNd",
        "outputId": "2a2696b8-530c-4321-cee6-d3f6a09222c1"
      },
      "source": [
        "from nltk.stem.wordnet import WordNetLemmatizer\n",
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "\n",
        "lmtzr = WordNetLemmatizer()\n",
        "\n",
        "# prepare corpus from the descriptions that dont have stopwords\n",
        " \n",
        "for i in range(len(df)):\n",
        " \n",
        "  corpus = df['Clean_Full_Descriptions_no_stop'][i]\n",
        "\n",
        "#tokenize words\n",
        "  tokenized_corpus = nltk.word_tokenize(corpus)\n",
        "\n",
        "# lemmatize these tokens\n",
        "  lemmatized_tokens = [lmtzr.lemmatize(token) for token in tokenized_corpus]\n",
        "\n",
        "# word frequencies for the lemmatized tokens\n",
        "  fd= nltk.FreqDist(lemmatized_tokens)\n",
        "  top_words = []\n",
        "  words=pd.Series([])\n",
        "  for key, value in fd.items():\n",
        "    top_words.append((key))\n",
        "    words[i]=top_words\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ve0NY3k7HyzH"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "vectorizer = CountVectorizer(max_features= 1, min_df=1, max_df=1.2, stop_words=stopwords.words('english'))\n",
        "X = vectorizer.fit_transform(top_words_res).toarray()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7AeWOtrtMQg_"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "vectorizer = CountVectorizer(max_features=1, min_df=1, max_df=1.2, stop_words=stopwords.words('english'))\n",
        "Y = vectorizer.fit_transform(top_words).toarray()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kpz1gxPCPVQ7"
      },
      "source": [
        "Y = Y[30:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tU6I62FbmM9w",
        "outputId": "afeeb3d7-3614-41e3-d3fa-8ab55ae64b16"
      },
      "source": [
        "Y.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(22, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 181
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eggQLBVTQDMf",
        "outputId": "551991bb-b3d1-4b38-82c1-ebd80ec08640"
      },
      "source": [
        "X.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(22, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 182
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ckiWkc_DOrx3",
        "outputId": "15dad67f-7a8b-4613-a983-8fef499d7efa"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "logreg = LogisticRegression()\n",
        "logreg.fit(X, Y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
              "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
              "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 183
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VrIFYb9cVIYp"
      },
      "source": [
        "prediction = logreg.predict(Y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n_KkabukSly1",
        "outputId": "bc08369c-6fa6-41fd-dc2f-b4dfbd53c338"
      },
      "source": [
        "print(classification_report(Y,prediction))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      1.00      0.98        21\n",
            "           1       0.00      0.00      0.00         1\n",
            "\n",
            "    accuracy                           0.95        22\n",
            "   macro avg       0.48      0.50      0.49        22\n",
            "weighted avg       0.91      0.95      0.93        22\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QLkt0z3mVmeR",
        "outputId": "82cc88e5-1d3b-4594-fe15-91a160cb81e5"
      },
      "source": [
        "ridge = RidgeClassifier() \n",
        "ridge.fit(X,Y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_ridge.py:940: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,\n",
              "                max_iter=None, normalize=False, random_state=None,\n",
              "                solver='auto', tol=0.001)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 187
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QXDY-NbPWAN1"
      },
      "source": [
        "prediction_1 = ridge.predict(Y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9WIvIcpIWF7l",
        "outputId": "f3957824-4475-4819-ff1b-5a86447d1ed2"
      },
      "source": [
        "print(classification_report(Y,prediction_1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      1.00      0.98        21\n",
            "           1       0.00      0.00      0.00         1\n",
            "\n",
            "    accuracy                           0.95        22\n",
            "   macro avg       0.48      0.50      0.49        22\n",
            "weighted avg       0.91      0.95      0.93        22\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J_Ap5cKlWF1C",
        "outputId": "f95d6b21-0850-432f-ddaa-fe1ede4d858b"
      },
      "source": [
        "neigh = KNeighborsClassifier()\n",
        "neigh.fit(X,Y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
              "                     metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
              "                     weights='uniform')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 190
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bkQPJQStWVKY"
      },
      "source": [
        "prediction_2 = neigh.predict(Y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EXiHeHcjWbNa",
        "outputId": "da3abcee-0817-4aa0-aee9-634195368bee"
      },
      "source": [
        "print(classification_report(Y,prediction_2))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      1.00      0.98        21\n",
            "           1       0.00      0.00      0.00         1\n",
            "\n",
            "    accuracy                           0.95        22\n",
            "   macro avg       0.48      0.50      0.49        22\n",
            "weighted avg       0.91      0.95      0.93        22\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}